# 13 GB text
# Wikipedia en 40%
# Wikipedia ja 80%
# Failed at 96 GB RAM
# ---
# 7.3 GB text
# Wikipedia en 20%
# Wikipedia ja 40%
# Failed at 96 GB RAM
# ---
# 3.7 GB text
# Wikipedia en 10%
# Wikipedia ja 10%

python src/tokenizer/text.py > tmp/tokenizer_train.txt
